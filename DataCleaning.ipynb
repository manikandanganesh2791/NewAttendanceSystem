{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_file = open('attendance_s_clean.csv', 'w')\n",
    "attendance_s = open('attendance_s.csv', 'r')\n",
    "row_s = attendance_s.read().splitlines()\n",
    "row_list = []\n",
    "record_dict = {}\n",
    "date_split_list = []\n",
    "date_val = \"\"\n",
    "target_line = \"\"\n",
    "\n",
    "#Method list_val is used to clean the attendance_s.csv file by returning only\n",
    "#the set of rows having unique Id and eliminates the redundant Id values.\n",
    "#Also, this method parses the datein and dateout column values by stripping\n",
    "#the date of the format mm/dd/yyyy and removing the time values from it.\n",
    "\n",
    "def list_val(row_list):\n",
    "    result = []\n",
    "    for i in range(len(row_list)):\n",
    "        date_val = \"\"\n",
    "        time_val = \"\"\n",
    "        date_split_list = []\n",
    "        if(i != 0):\n",
    "            if(i==3):\n",
    "                if(row_list[i] != 'NULL'):\n",
    "                    date_split_list=row_list[i].split(\" \")\n",
    "                    date_val=date_split_list[0]\n",
    "                    time_val=date_split_list[1]\n",
    "                    result.append(date_val)\n",
    "                    result.append(time_val)\n",
    "                else:\n",
    "                    result.append(row_list[i])\n",
    "                    result.append(row_list[i])\n",
    "            elif(i==6):\n",
    "                if(row_list[i] != 'NULL'):\n",
    "                    date_split_list=row_list[i].split(\" \")\n",
    "                    date_val=date_split_list[0]\n",
    "                    time_val=date_split_list[1]\n",
    "                    result.append(date_val)\n",
    "                    result.append(time_val)\n",
    "                else:\n",
    "                    result.append(row_list[i])\n",
    "                    result.append(row_list[i])\n",
    "            else:\n",
    "                result.append(row_list[i])\n",
    "    return result\n",
    "\n",
    "#Loop that forms the dictionary 'record_dict' to store the records from \n",
    "#attendance_s.csv file having the key as Id and values as a list carrying\n",
    "#CardSourceId, CardHolderId, DateIn, DateOut and HoursWorked values\n",
    "#for CardSourceId '73'\n",
    "for line in row_s[1:]:\n",
    "    row_list = line.split(\",\")\n",
    "    if(row_list[1] == '73'):\n",
    "        if(row_list[0] in record_dict):\n",
    "            continue\n",
    "        record_dict[row_list[0]] = list_val(row_list)\n",
    "column_header = 'ID'+','+'CardSourceID'+','+\"CardHolderID\"+','+\"DateIn\"+','+\"InTime\"+','+\"ReportField1\"+','+\"ReportField2\"+','+\"DateOut\"+','+\"OutTime\"+','+\"HoursWorked\"\n",
    "target_file.write(column_header)\n",
    "target_file.write(\"\\n\")\n",
    "for key, value in record_dict.items():\n",
    "    target_line = \"\"\n",
    "    target_line+=key\n",
    "    for i in range(len(value)):\n",
    "        target_line+=\",\"+value[i]\n",
    "    target_file.write(target_line)\n",
    "    target_file.write(\"\\n\")\n",
    "target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_target_file = open('attendance_c_intermediate.csv', 'w')\n",
    "c_target_inconsistent = open('attendance_c_inconsistentlist.csv', 'w')\n",
    "attendance_c_inconsistent = open('attendance_c_inconsistent.csv', 'r')\n",
    "attendance_c_consistent = open('attendance_c_consistent.csv', 'r')\n",
    "row_c_inconsistent = attendance_c_inconsistent.readlines()\n",
    "row_c_consistent = attendance_c_consistent.readlines()\n",
    "row_list_inc = []\n",
    "row_list_inc_add=[]\n",
    "row_list_inconsistent_final = []\n",
    "row_list_consistent_final = []\n",
    "row_list_con=[]\n",
    "row_list_con_add=[]\n",
    "dict_inc = {}\n",
    "flag = False\n",
    "line_string = \"\"\n",
    "row_add_inc_list=[]\n",
    "row_inc_result_list=[]\n",
    "\n",
    "for i in row_c_inconsistent:\n",
    "    row_list_inc_add=[]\n",
    "    a = i.replace('\\r','').strip()\n",
    "    row_list_inc = a.split(',')\n",
    "    if row_list_inc[4] in dict_inc:\n",
    "        row_list_inc_add.append(row_list_inc[1])\n",
    "        row_list_inc_add.append(row_list_inc[2])\n",
    "        row_list_inc_add.append(row_list_inc[3])\n",
    "        dict_inc[row_list_inc[4]].append(row_list_inc_add)\n",
    "    else:\n",
    "        row_list_inc_add.append(row_list_inc[1])\n",
    "        row_list_inc_add.append(row_list_inc[2])\n",
    "        row_list_inc_add.append(row_list_inc[3])\n",
    "        dict_inc[row_list_inc[4]] = []\n",
    "        dict_inc[row_list_inc[4]].append(row_list_inc_add)\n",
    "for i,j in dict_inc.items():\n",
    "    row_list_inc_add = j\n",
    "    for k in range(len(row_list_inc_add)):\n",
    "        flag = False\n",
    "        if k == 0:\n",
    "            prime_status = row_list_inc_add[k][2]\n",
    "        else:\n",
    "            if row_list_inc_add[k][2] != prime_status:\n",
    "                flag = True\n",
    "                row_list_inconsistent_final.append([(row_list_inc_add[k][0]+',' + row_list_inc_add[k][1])])\n",
    "                break\n",
    "    if(flag==False):\n",
    "        row_list_consistent_final.append(row_list_inc_add[0])\n",
    "column_header = \"CardHolderID\" + ',' + \"Date\"\n",
    "c_target_inconsistent.write(column_header)\n",
    "c_target_inconsistent.write('\\n')\n",
    "for i in range(len(row_list_inconsistent_final)):\n",
    "    row_list_inc_add=row_list_inconsistent_final[i]\n",
    "    line_string=\"\"\n",
    "    line_string+=row_list_inc_add[0]\n",
    "    c_target_inconsistent.write(line_string)\n",
    "    c_target_inconsistent.write('\\n')\n",
    "c_target_inconsistent.close()\n",
    "column_header = \"CardHolderID\" + ',' + \"Date\" + ',' + \"Status\"\n",
    "c_target_file.write(column_header)\n",
    "c_target_file.write('\\n')\n",
    "i_count=0\n",
    "for i in row_c_consistent:\n",
    "    i_count+=1\n",
    "    a = i.replace('\\r','').strip()\n",
    "    row_list_con=a.split(',')\n",
    "    line_string=\"\"\n",
    "    for j in range(len(row_list_con)):\n",
    "        if j in (1,2):\n",
    "            if j==1:\n",
    "                a = row_list_con[j].replace('\"','')\n",
    "                line_string+=a+','\n",
    "            else:\n",
    "                line_string+=row_list_con[j]+','\n",
    "        elif j == 3:\n",
    "            line_string+=row_list_con[j]\n",
    "    c_target_file.write(line_string)\n",
    "    c_target_file.write('\\n')\n",
    "for i in row_list_consistent_final:\n",
    "    a = i[0].replace('\"','')\n",
    "    line_string=a+','+i[1]+','+i[2]\n",
    "    c_target_file.write(line_string)\n",
    "    c_target_file.write('\\n')\n",
    "c_target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_file= open('attendance_s_consistent.csv', 'w')\n",
    "inconsistent_main = open('intermediate_inconsistent.csv','r')\n",
    "consistent_main = open('intermediate_consistent.csv','r')\n",
    "row_inconsistent = inconsistent_main.read().splitlines()\n",
    "row_consistent = consistent_main.read().splitlines()\n",
    "row_inconsistent_list = []\n",
    "row_consistent_list=[]\n",
    "row_inconsistent_add_list=[]\n",
    "row_inconsistent_result=[]\n",
    "id_date_set=set()\n",
    "flag = False\n",
    "line_string = \"\"\n",
    "for i in row_inconsistent:\n",
    "    row_inconsistent_list.append(i.split(\",\"))\n",
    "row_inconsistent_result=[]\n",
    "for i in range(len(row_inconsistent_list)-1):\n",
    "    if row_inconsistent_list[i][1]+'|'+row_inconsistent_list[i][2] not in id_date_set:\n",
    "        date_val=row_inconsistent_list[i][2]\n",
    "        id_val=row_inconsistent_list[i][1]\n",
    "        status_val = row_inconsistent_list[i][3]\n",
    "        j=i+1\n",
    "        while(j<len(row_inconsistent_list)):\n",
    "            flag = False\n",
    "            if row_inconsistent_list[j][1] == id_val and row_inconsistent_list[j][2] == date_val:\n",
    "                if row_inconsistent_list[j][3] != status_val:\n",
    "                    flag = True\n",
    "                    row_inconsistent_add_list=[]\n",
    "                    row_inconsistent_add_list.append(row_inconsistent_list[j][1])\n",
    "                    row_inconsistent_add_list.append(row_inconsistent_list[j][2])\n",
    "                    row_inconsistent_add_list.append('tardy and Early departure')\n",
    "                    row_inconsistent_result.append(row_inconsistent_add_list)\n",
    "                    id_date_set.add(row_inconsistent_list[j][1]+'|'+row_inconsistent_list[j][2])\n",
    "                    break\n",
    "                else:\n",
    "                    j+=1\n",
    "            else:\n",
    "                flag = True\n",
    "                row_inconsistent_add_list=[]\n",
    "                row_inconsistent_add_list.append(row_inconsistent_list[j-1][1])\n",
    "                row_inconsistent_add_list.append(row_inconsistent_list[j-1][2])\n",
    "                row_inconsistent_add_list.append(row_inconsistent_list[j-1][3])\n",
    "                row_inconsistent_result.append(row_inconsistent_add_list)\n",
    "                id_date_set.add(row_inconsistent_list[j-1][1]+'|'+row_inconsistent_list[j-1][2])\n",
    "                break\n",
    "        if flag == False:\n",
    "            row_inconsistent_add_list=[]\n",
    "            row_inconsistent_add_list.append(id_val)\n",
    "            row_inconsistent_add_list.append(date_val)\n",
    "            row_inconsistent_add_list.append(status_val)\n",
    "            row_inconsistent_result.append(row_inconsistent_add_list)\n",
    "            id_date_set.add(id_val+'|'+date_val)\n",
    "            break\n",
    "\n",
    "column_header = 'CardHolderID' + ',' + 'Event_Date' + ',' + 'Status'\n",
    "target_file.write(column_header)\n",
    "target_file.write('\\n')\n",
    "for i in row_consistent:\n",
    "    line_string = \"\"\n",
    "    row_consistent_list=i.split(\",\")\n",
    "    for j in range(len(row_consistent_list)):\n",
    "        if j not in (0,3,4):\n",
    "            line_string+=row_consistent_list[j]+','\n",
    "        elif j == 3:\n",
    "            line_string+=row_consistent_list[j]\n",
    "    target_file.write(line_string)\n",
    "    target_file.write('\\n')\n",
    "for i in row_inconsistent_result:\n",
    "    line_string = \"\"\n",
    "    for j in range(len(i)):\n",
    "        if j != 2:\n",
    "            line_string+=i[j]+','\n",
    "        else:\n",
    "            line_string+=i[j]\n",
    "    target_file.write(line_string)\n",
    "    target_file.write('\\n')\n",
    "target_file.close()\n",
    "inconsistent_main.close()\n",
    "consistent_main.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_file_k = open('attendance_k_intermediate.csv', 'w')\n",
    "attendance_k_inconsistent = open('inconsistent_k.csv','r')\n",
    "attendance_k = open('attendance_k_inconsistent.csv','r')\n",
    "row_k=attendance_k.readlines()\n",
    "row_k_inc=attendance_k_inconsistent.readlines()\n",
    "row_k_inc_list=[]\n",
    "row_k_con_list=[]\n",
    "row_k_list=[]\n",
    "row_k_set=set()\n",
    "row_k_dict={}\n",
    "line_string=\"\"\n",
    "flag = False\n",
    "for i in row_k_inc:\n",
    "    row_k_list=[]\n",
    "    a = i.replace('\\r','').strip()\n",
    "    row_k_list=a.split(\",\")\n",
    "    if row_k_list[1]+'|'+row_k_list[2] not in row_k_set:\n",
    "        row_k_set.add(row_k_list[1]+'|'+row_k_list[2])\n",
    "    row_k_inc_list.append(row_k_list)\n",
    "    if row_k_list[1]+'|'+ row_k_list[2] not in row_k_dict:\n",
    "        row_k_dict[row_k_list[1]+'|'+row_k_list[2]] = []\n",
    "        row_k_dict[row_k_list[1]+'|'+row_k_list[2]].append(row_k_list[3])\n",
    "    else:\n",
    "        row_k_dict[row_k_list[1]+'|'+row_k_list[2]].append(row_k_list[3])\n",
    "for i in row_k:\n",
    "    row_k_list=[]\n",
    "    a = i.replace('\\r','').strip()\n",
    "    row_k_list=a.split(',')\n",
    "    if row_k_list[1]+'|'+row_k_list[2] not in row_k_set:\n",
    "        card_id = row_k_list[1].replace('\"','')\n",
    "        line_string=card_id+','+row_k_list[2]+','+row_k_list[3]\n",
    "        target_file_k.write(line_string)\n",
    "        target_file_k.write('\\n')\n",
    "row_k_inc_list=[]\n",
    "row_k_con_dup_list=[]\n",
    "for k,v in row_k_dict.items():\n",
    "    flag = False\n",
    "    prime_status = v[0]\n",
    "    for i in range(1,len(v)):\n",
    "        if v[i] != prime_status:\n",
    "            flag = True\n",
    "            row_k_inc_list.append(k)\n",
    "            break\n",
    "    if flag == False:\n",
    "        row_k_con_dup_list.append([k])\n",
    "        row_k_con_dup_list.append(v[1])\n",
    "        for i in range(len(row_k_con_dup_list)):\n",
    "            id_dateval = row_k_con_dup_list[0]\n",
    "            fetch_list=id_dateval.split(\"|\")\n",
    "            fetch_list.append(row_k_con_dup_list[1])\n",
    "            line_string=\"\"\n",
    "            card_id = fetch_list[0].replace('\"','')\n",
    "            line_string=card_id+','+fetch_list[1]+','+fetch_list[2]\n",
    "            target_file_k.write(line_string)\n",
    "            target_file_k.write('\\n')\n",
    "target_file_k.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8/30/2016', '9/1/2016', '2/9/2017', '3/14/2017', '4/10/2017']\n"
     ]
    }
   ],
   "source": [
    "attendance_source = open('attendance_main.csv','r')\n",
    "attendance_main=open('List of school days .csv','r')\n",
    "row_source = attendance_source.readlines()\n",
    "row_main=attendance_main.read().splitlines()\n",
    "row_source_list=[]\n",
    "row_source_set = set()\n",
    "row_source_targetlist=[]\n",
    "for i in row_source:\n",
    "    a = i.replace('\\r','')\n",
    "    row_source_list=a.split(',')\n",
    "    b = row_source_list[2].replace('\"','')\n",
    "    if b not in row_source_set:\n",
    "        row_source_set.add(b)\n",
    "\n",
    "for i in row_main[1:]:\n",
    "    if i not in row_source_set:\n",
    "        row_source_targetlist.append(i)\n",
    "print row_source_targetlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
